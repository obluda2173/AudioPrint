#+title: Plan
#+author: Erik An
#+email: obluda2173@gmail.com
#+date: <2025-12-21>
#+lastmod: <2025-12-24 18:50>
#+options: num:t
#+startup: overview

* General Structure

#+begin_src
AudioPrint/
├── src/                     # Main Source Code Package
│   ├── __init__.jl
│   ├── dsp.jl               # Signal processing (FFT, Spectrograms)
│   ├── fingerprint.jl       # Logic to find peaks and generate hashes
│   ├── database.jl          # SQL interactions (insert/query hashes)
│   └── recognize.jl         # The "Controller" that ties it all together
├── data/
│   ├── db/                  # SQLite database file location
│   └── songs/               # Raw MP3 files for testing
├── tests/                   # Unit tests
├── requirements.org         # Dependencies
├── manage.py                # CLI tool
└── README.md
#+end_src

* Detailed Structure

- *Module 1: dsp.jl* (the ears)

  *Responsibility*: Convert the .mp3 files to 2D array (spectrogram)

  *API*: Function should return the Matrix{Float32} in which:

  - *Y-Axis*: Frequency Bins (Low pitch to High pitch)
  - *X-Axis*: Time Frames (From Start of song to end)
  - *Value*: =A[i,j]= The Volume (Amplitude/Magnitude) of that specific frequency at that specific time.

    |---------------+--------+---------------+--------+-----|
    | Indices       | Time 1 | Time 2 (10ms) | Time 3 | ... |
    |---------------+--------+---------------+--------+-----|
    | Freq 1 (0Hz)  |   0.01 | 0.02          |   0.01 | ... |
    |---------------+--------+---------------+--------+-----|
    | Freq 2 (43Hz) |   0.05 | 0.99 (PEAK)   |   0.12 | ... |
    |---------------+--------+---------------+--------+-----|
    | Freq 3 (86Hz) |   0.02 | 0.15          |   0.02 | ... |
    |---------------+--------+---------------+--------+-----|
    | ...           |    ... | ...           |    ... | ... |
    |---------------+--------+---------------+--------+-----|


- *Module 2: fingerprint.jl* (the brain)

  *Responsibility*: Find "peaks" in the spectrogram and turn them into hashes.

  *Logic*:
  1. *Find Peaks*: Look at the 2D spectrograms. Find the points that are louder than their neighbours (local maxima).

  2. *Filter*: Keep only the strongest peaks to reduce noise.

  3. *Hash Generation*: Hash pair of peaks.
     - Take an "Anchor Point" (A).
     - Find the "Target Point" (B) nearby in time.
     - Create a signature: =Hash = (Frequency_A) + (Frequency_B) + (Time_Delta)=.


- *Module 3: recognize.jl* (The Matcher)

  *Responsibility*: Compare a noisy recording to the database.

  - *The "Alignment" Logic*: You cannot just count how many hashes match. A hash might match by coincidence. You must check if the relative timing is correct.

    - Equation: =Real_Song_Start_Time = Database_Offset - Recording_Offset=

    - If a song is a true match, the difference between the database timestamp and the recording timestamp will be constant for many hashes.

* High-Level Architecture

The system should have two distinct workflows:
- Fingerprinting (Enrollment) and
- Recognition (Querying)

* The Database Schema
We need two tables. Simplicity is key here; speed comes from indexing the =hash=.

- =songs= Table:

  - =id= (Integer, Primary Key)

  - =name= (String)

  - =artist= (String, optional)

- =fingerprints= Table:

  - =hash= (String/Binary): The generated unique ID for a specific constellation of frequencies. (Index this column!)

  - =song_id= (Integer): Foreign key to the =songs= table.

  - =offset= (Integer): The time (in milliseconds or window index) where this hash appeared in the song.

* Q&A

- *What is a spectrogram?*

  A spectrogram is a visual graph showing a signal's frequency changes over time, mapping *time* (horizontal axis), *frequency* (vertical axis), and *amplitude/intensity* (color/brightness) all in one image, allowing you to /"see"/ sound or other signals by revealing how their frequency content evolves.

  Example:
  [[file:media/spectrogram_example.png][spectrogram_example.png]]

* Resources

- [[https://www.ee.columbia.edu/~dpwe/papers/Wang03-shazam.pdf][The Bible of Audio Fingerprint]]
- [[https://github.com/mdeff/fma?tab=readme-ov-file][Archive with datasets]]
